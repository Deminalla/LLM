{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZunLkmln1jcbpZe09xfjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deminalla/Kursinis/blob/main/fta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CQEijbowISJ",
        "outputId": "b57ca5d1-c053-4c7f-dad7-25d5519baf61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H-u4uI7Cn1s3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "file_path = 'FTA_dataset.xlsx'\n",
        "sheet1 = pd.read_excel(file_path, sheet_name='FTA', header=None)\n",
        "sheet2 = pd.read_excel(file_path, sheet_name='NFTA', header=None)\n",
        "\n",
        "sheet1.columns = ['paragraph']\n",
        "sheet2.columns = ['paragraph']\n",
        "sheet1['fta'] = 1\n",
        "sheet2['fta'] = 0\n",
        "\n",
        "data = pd.concat([sheet1, sheet2], ignore_index=True)\n",
        "\n",
        "# Shuffle the data\n",
        "# sample() - randomly select data\n",
        "# frac=1 - select 100% of data\n",
        "# After shuffling, the original index of the DataFrame is no longer in order\n",
        "# reset_index(drop=True) is used to reset the index to a new sequential order.\n",
        "# drop=True - discards the old index\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# training (70%), validation (10%), and test (20%)\n",
        "train, temp = train_test_split(data, test_size=0.3, random_state=42)\n",
        "val, test = train_test_split(temp, test_size=(2/3), random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FTA sheet:\")\n",
        "print(sheet1[['paragraph', 'fta']].head()) # Display first 5 rows\n",
        "\n",
        "print(\"\\nNFTA sheet:\")\n",
        "print(sheet2[['paragraph', 'fta']].head())\n",
        "\n",
        "print(\"\\nData after combining and shuffling:\")\n",
        "print(data[['paragraph', 'fta']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RYvwvvKokt0",
        "outputId": "adbdf32c-8128-4e0c-f746-9710e253ed5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FTA sheet:\n",
            "                                           paragraph  fta\n",
            "0  Lietuvai nereikia Liberalų sąjūdžio, jos lyder...    1\n",
            "1     palaukit, nenutraukit, korumpuotas žurnaliste.    1\n",
            "2  Mes nesižarstome skaičiais, mes nežadame, Liet...    1\n",
            "3  mokesčių sistema, kuri buvo per naktinę reform...    1\n",
            "4                                             Vagys!    1\n",
            "\n",
            "NFTA sheet:\n",
            "                                           paragraph  fta\n",
            "0  Mes, Lietuvos Laisvės sąjunga, esame pirmoji p...    0\n",
            "1  Labas vakaras. Na, kad būtų žmogus laimingas, ...    0\n",
            "2  Tai jeigu mes esame užsienio politikoj šiandie...    0\n",
            "3  Na, daug yra kalbama apie laimės indeksą, bet ...    0\n",
            "4  Kaip mūsų žmonės jausis Lietuvoje, koks bus po...    0\n",
            "\n",
            "Data after combining and shuffling:\n",
            "                                           paragraph  fta\n",
            "0  Čia klausimas, kaip čia pasakyt, jis nueina į ...    0\n",
            "1  Eikit sau, kaip man patinka, kaip jūs čia šnek...    1\n",
            "2  Pirmiausia, mieli kolegos, klausimas yra tame:...    0\n",
            "3  Monopolinės paslaugos tai yra šilumos tiekimas...    0\n",
            "4  Mūsų krašto beveik trečdalis yra už sienos, no...    0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using huggingface libs\n",
        "!pip install -q transformers\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import LongformerTokenizer, LongformerModel"
      ],
      "metadata": {
        "id": "pi0PlBZkbDZS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# doing the tokenization to prep data as tokens\n",
        "preprocessed_data = []\n",
        "\n",
        "for t in data['paragraph']:\n",
        "  encoded_input = tokenizer(t, return_tensors='pt')\n",
        "  preprocessed_data.append(encoded_input)"
      ],
      "metadata": {
        "id": "ibUj86paZo01"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# calculating last hidden states and everaging to have fixed dimmention features for each text\n",
        "outputs = []\n",
        "\n",
        "for inputs in tqdm(preprocessed_data, desc=\"Processing Data\", unit=\"batch\"):\n",
        "    output = model(**inputs)\n",
        "    features = np.mean(output[0].detach().numpy(), axis=1)\n",
        "    outputs.append(features)"
      ],
      "metadata": {
        "id": "Qs_nkI4newks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# extracted features\n",
        "outputs[0].shape, outputs[1].shape, outputs[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQeRcBGBa2h5",
        "outputId": "f07c1f49-6933-4ed9-f2d8-be53de9d77b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1, 768), (1, 768), (1, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we can compare features\n",
        "cosine_similarity(outputs[0], outputs[1])"
      ],
      "metadata": {
        "id": "wVNQr_utapwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b56e829-a1a9-4589-d3fd-1c4ec802d279"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84704214]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(outputs[0], outputs[2])"
      ],
      "metadata": {
        "id": "7u8pAwgAay_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883718f7-f3ce-4be5-f80a-bf4338850895"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.881665]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}